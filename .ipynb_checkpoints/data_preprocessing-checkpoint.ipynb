{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7a689f-c9e4-4ad7-a102-93b73ba790c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform xml to csv it take 3 parameters inputfile with adreess output file with adreess and the name of the field\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def convert_xml_to_csv(input_file, output_file, field_name):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        \n",
    "        # Write CSV header\n",
    "        csvwriter.writerow(['id', field_name])\n",
    "        \n",
    "        # Write the CSV report\n",
    "        for report in root.findall('report'):\n",
    "            report_id = report.get('id')\n",
    "            for update in report.findall('update'):\n",
    "                field_value = update.find('what').text\n",
    "                csvwriter.writerow([report_id, field_value])\n",
    "    \n",
    "    print(f\"XML file {input_file} has been converted to CSV file {output_file} based on the field '{field_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3483a30-f553-4b63-8928-9a91aa97d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f4f6df-5c33-404d-8361-a97fed60e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function call for the converting xml to csv \n",
    "# input_file=\"mozilla/Bugzilla/severity.xml\"\n",
    "# output_file=\"processed data/Bugzilla/severity.csv\"\n",
    "# convert_xml_to_csv(input_file, output_file, 'severity')\n",
    "\n",
    "# input_file=\"mozilla/Bugzilla/short_desc.xml\"\n",
    "# output_file=\"processed data/Bugzilla/short_desc.csv\"\n",
    "# convert_xml_to_csv(input_file, output_file, 'description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf66787-7a0d-4fda-9f1b-489c5f862255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove duplication from the csv file \n",
    "\n",
    "def removeduplicate(input_file,output_file):\n",
    "    with open(input_file, 'r',encoding=\"utf-8\") as input_file, open(output_file, 'w', newline='',encoding=\"utf-8\") as output_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        writer = csv.writer(output_file)\n",
    "        seen = set()  # keep track of seen values\n",
    "        for row in reader:\n",
    "            if row[0] not in seen:  # if value hasn't been seen before\n",
    "                seen.add(row[0])\n",
    "                writer.writerow(row)\n",
    "        print(f\"all duplicates formm has been removed and output file is created \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e76db8-197c-4456-8f95-9fa75ef48c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call for removind duplicates in csv\n",
    "# input_file=\"processed data/Bugzilla/severity.csv\"\n",
    "# output_file=\"processed data/Bugzilla/severity_cleaned.csv\"\n",
    "# removeduplicate(input_file,output_file)\n",
    "\n",
    "# # function call for removind duplicates in csv\n",
    "# input_file=\"processed data/Bugzilla/short_desc.csv\"\n",
    "# output_file=\"processed data/Bugzilla/short_desc_cleaned.csv\"\n",
    "# removeduplicate(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52abbe21-9564-4b5c-83ee-0060bde3cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge 2 csv file\n",
    "def merge(file1,file2,output_file):\n",
    "    df = pd.read_csv(file1)\n",
    "    df1 = pd.read_csv(file2)\n",
    "\n",
    "    # Merge the data frames on the 'id' field\n",
    "    merged_df = pd.merge(df, df1, on='id', how='inner')\n",
    "\n",
    "    # Write the merged data frame to a CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"File merged\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3c00a3-0b35-4198-b7fa-ef05d70c2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file1 = \"processed data/Bugzilla/severity_cleaned.csv\"\n",
    "# file2 = \"processed data/Bugzilla/short_desc_cleaned.csv\"\n",
    "# output_file = \"processed data/Bugzilla/Bugzilla.csv\"\n",
    "# merge(file1,file2,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d18dda90-f2d2-4b88-b441-88c33c9fc2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML file mozilla/Bugzilla/severity.xml has been converted to CSV file processed data/Bugzilla/severity.csv based on the field 'severity'.\n",
      "XML file mozilla/Bugzilla/short_desc.xml has been converted to CSV file processed data/Bugzilla/short_desc.csv based on the field 'description'.\n",
      "XML file mozilla/Core/severity.xml has been converted to CSV file processed data/Core/severity.csv based on the field 'severity'.\n",
      "XML file mozilla/Core/short_desc.xml has been converted to CSV file processed data/Core/short_desc.csv based on the field 'description'.\n",
      "XML file mozilla/Firefox/severity.xml has been converted to CSV file processed data/Firefox/severity.csv based on the field 'severity'.\n",
      "XML file mozilla/Firefox/short_desc.xml has been converted to CSV file processed data/Firefox/short_desc.csv based on the field 'description'.\n",
      "XML file mozilla/Thunderbird/severity.xml has been converted to CSV file processed data/Thunderbird/severity.csv based on the field 'severity'.\n",
      "XML file mozilla/Thunderbird/short_desc.xml has been converted to CSV file processed data/Thunderbird/short_desc.csv based on the field 'description'.\n"
     ]
    }
   ],
   "source": [
    "# list of list caontaing input file and output file infoe of each application\n",
    "file_info_xml_to_csv = [\n",
    "    [\"mozilla/Bugzilla/severity.xml\", \"processed data/Bugzilla/severity.csv\", \"severity\"],\n",
    "    [\"mozilla/Bugzilla/short_desc.xml\", \"processed data/Bugzilla/short_desc.csv\", \"description\"],\n",
    "    \n",
    "    [\"mozilla/Core/severity.xml\", \"processed data/Core/severity.csv\", \"severity\"],\n",
    "    [\"mozilla/Core/short_desc.xml\", \"processed data/Core/short_desc.csv\", \"description\"],\n",
    "    \n",
    "    [\"mozilla/Firefox/severity.xml\", \"processed data/Firefox/severity.csv\", \"severity\"],\n",
    "    [\"mozilla/Firefox/short_desc.xml\", \"processed data/Firefox/short_desc.csv\", \"description\"],\n",
    "    \n",
    "    [\"mozilla/Thunderbird/severity.xml\", \"processed data/Thunderbird/severity.csv\", \"severity\"],\n",
    "    [\"mozilla/Thunderbird/short_desc.xml\", \"processed data/Thunderbird/short_desc.csv\", \"description\"]\n",
    "]\n",
    "\n",
    "# for loop for acessing input file , output file and field name of each applicatin line by line and calling xml to csv function\n",
    "for info in file_info_xml_to_csv:\n",
    "    input_file = info[0]\n",
    "    output_file = info[1]\n",
    "    field_name = info[2]\n",
    "    convert_xml_to_csv(input_file, output_file, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c993f12-0681-4130-ad64-22f39e7b0b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n"
     ]
    }
   ],
   "source": [
    "# list of inputfile and outputfile for removing the duplicates \n",
    "file_info_remove_duplicate = [\n",
    "    [\"processed data/Bugzilla/severity.csv\", \"processed data/Bugzilla/severity_cleaned.csv\"],\n",
    "    [\"processed data/Bugzilla/short_desc.csv\", \"processed data/Bugzilla/short_desc_cleaned.csv\"],\n",
    "    \n",
    "    [\"processed data/Core/severity.csv\", \"processed data/Core/severity_cleaned.csv\"],\n",
    "    [\"processed data/Core/short_desc.csv\", \"processed data/Core/short_desc_cleaned.csv\"],\n",
    "    \n",
    "    [\"processed data/Firefox/severity.csv\", \"processed data/Firefox/severity_cleaned.csv\"],\n",
    "    [\"processed data/Firefox/short_desc.csv\", \"processed data/Firefox/short_desc_cleaned.csv\"],\n",
    "    \n",
    "    [\"processed data/Thunderbird/severity.csv\", \"processed data/Thunderbird/severity_cleaned.csv\"],\n",
    "    [\"processed data/Thunderbird/short_desc.csv\", \"processed data/Thunderbird/short_desc_cleaned.csv\"],\n",
    "]\n",
    "\n",
    "#for loop for acessing input file and output file and calling remove duplicate function\n",
    "\n",
    "for info in file_info_remove_duplicate:\n",
    "    input_file = info[0]\n",
    "    output_file = info[1]\n",
    "    removeduplicate(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409467e0-6031-4c93-9be4-0c446678d99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d260ac42-f846-4160-a7e7-3a49150739fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File merged\n",
      "File merged\n",
      "File merged\n",
      "File merged\n"
     ]
    }
   ],
   "source": [
    "# list of fules to merge \n",
    "file_info_merge = [\n",
    "    [\"processed data/Bugzilla/severity_cleaned.csv\",\"processed data/Bugzilla/short_desc_cleaned.csv\",\"processed data/Bugzilla/Bugzilla_merged.csv\"],\n",
    "    \n",
    "    [\"processed data/Core/severity_cleaned.csv\",\"processed data/Core/short_desc_cleaned.csv\",\"processed data/Core/Core_merged.csv\"],\n",
    "\n",
    "    [\"processed data/Thunderbird/severity_cleaned.csv\",\"processed data/Thunderbird/short_desc_cleaned.csv\",\"processed data/Thunderbird/Thunderbird_merged.csv\"],\n",
    "    \n",
    "    [\"processed data/Firefox/severity_cleaned.csv\",\"processed data/Firefox/short_desc_cleaned.csv\",\"processed data/Firefox/Firefox_merged.csv\"],\n",
    "    \n",
    "]\n",
    "\n",
    "for info in file_info_merge:\n",
    "    file1 = info[0]\n",
    "    file2 = info[1]\n",
    "    output_file = info[2]\n",
    "    merge(file1, file2, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b48647-7604-44c0-a431-9cc1b378b7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all file merged\n"
     ]
    }
   ],
   "source": [
    "file_info_merged = [\"processed data/Bugzilla/Bugzilla_merged.csv\",\"processed data/Core/Core_merged.csv\",\n",
    "                   \"processed data/Thunderbird/Thunderbird_merged.csv\",\"processed data/Firefox/Firefox_merged.csv\"\n",
    "                  ]\n",
    "\n",
    "# read in all four CSV files\n",
    "file1 = pd.read_csv(file_info_merged[0])\n",
    "file2 = pd.read_csv(file_info_merged[1])\n",
    "file3 = pd.read_csv(file_info_merged[2])\n",
    "file4 = pd.read_csv(file_info_merged[3])\n",
    "\n",
    "# merge the four files based on the 'id' field\n",
    "merged = pd.concat([file1, file2, file3, file4], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# write the merged dataframe to a new CSV file\n",
    "merged.to_csv('processed data/all_app_merged.csv', index=False)\n",
    "print(\"all file merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f0a6f40-d22c-42b2-8f7b-43ed3dccb5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168024, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed data/all_app_merged.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e49807d-9e6d-4054-988b-d247d2da64e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322620</td>\n",
       "      <td>normal</td>\n",
       "      <td>Logging in with 'Remember my Login' deselected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>322807</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>a spelling's mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322837</td>\n",
       "      <td>normal</td>\n",
       "      <td>[RFE] Unsubscribe from bug you've reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322462</td>\n",
       "      <td>minor</td>\n",
       "      <td>LDAP Authentication: if LDAPbinddn is defined,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323100</td>\n",
       "      <td>normal</td>\n",
       "      <td>'Boundary' line removed from multipart message...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     severity                                        description\n",
       "0  322620       normal  Logging in with 'Remember my Login' deselected...\n",
       "1  322807  enhancement                               a spelling's mistake\n",
       "2  322837       normal         [RFE] Unsubscribe from bug you've reported\n",
       "3  322462        minor  LDAP Authentication: if LDAPbinddn is defined,...\n",
       "4  323100       normal  'Boundary' line removed from multipart message..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1741a6-1057-43ac-963a-563bf3bdca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6502dd2d-e0ae-4ab4-969e-bfef7dc941c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "severity       0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85aee4f8-dbe4-47a3-9f75-73dea02d223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, severity, description]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicate_ids = df[df.duplicated(['id'])]\n",
    "# Print the duplicate rows\n",
    "print(duplicate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1b53bc5-b201-43c4-97b2-128c426d2fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         123472\n",
      "critical        16736\n",
      "major           16067\n",
      "minor            7546\n",
      "trivial          3165\n",
      "blocker           806\n",
      "enhancement       225\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df['severity'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813c58fb-a55f-467d-b36d-3ce0b6ed6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "normal =df[df.severity=='normal']\n",
    "major =df[df.severity=='major']\n",
    "minor =df[df.severity=='minor']\n",
    "blocker =df[df.severity=='blocker']\n",
    "trivial =df[df.severity=='trivial']\n",
    "critical =df[df.severity=='critical']\n",
    "enhancement =df[df.severity=='enhancement']\n",
    "\n",
    "def resample_df(df):\n",
    "    return resample(df,n_samples=123472)\n",
    "\n",
    "major =resample_df(major)\n",
    "minor =resample_df(minor)\n",
    "blocker =resample_df(blocker)\n",
    "trivial =resample_df(trivial)\n",
    "critical =resample_df(critical)\n",
    "enhancement =resample_df(enhancement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334cfb27-8945-4361-bbc0-a209d33a602c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235137d4-ad1f-46f1-9608-cbd6b1eac00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         123472\n",
      "major          123472\n",
      "minor          123472\n",
      "blocker        123472\n",
      "trivial        123472\n",
      "critical       123472\n",
      "enhancement    123472\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([normal,major,minor,blocker,trivial,critical,enhancement])\n",
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd42d5-a01c-4d29-a565-2a018e052f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f242484-35ca-484d-aaeb-90ac84d75542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948fe4f3-15e0-4e2c-a954-1dcb40061df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322620</td>\n",
       "      <td>normal</td>\n",
       "      <td>Logging in with 'Remember my Login' deselected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322837</td>\n",
       "      <td>normal</td>\n",
       "      <td>[RFE] Unsubscribe from bug you've reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323100</td>\n",
       "      <td>normal</td>\n",
       "      <td>'Boundary' line removed from multipart message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>323769</td>\n",
       "      <td>normal</td>\n",
       "      <td>\"Invalid Column Name\" when exportign bug list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>327624</td>\n",
       "      <td>normal</td>\n",
       "      <td>Missing space in attachment size error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id severity                                        description\n",
       "0   322620   normal  Logging in with 'Remember my Login' deselected...\n",
       "2   322837   normal         [RFE] Unsubscribe from bug you've reported\n",
       "4   323100   normal  'Boundary' line removed from multipart message...\n",
       "6   323769   normal  \"Invalid Column Name\" when exportign bug list ...\n",
       "11  327624   normal             Missing space in attachment size error"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('oversampled.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dbe1f7d-8c84-44a8-a6d4-148253e86d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"oversampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b54deb3-2adb-4420-9b13-0e17574e3f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864304, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554dc5d3-fe7d-41eb-9f99-2aea8694deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Read in the merged CSV file\n",
    "df = pd.read_csv('processed data/all_app_merged.csv')\n",
    "\n",
    "# Filter out rows where the description only contains one word\n",
    "df = df[df['description'].apply(lambda x: len(str(x).split()) > 1)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "df.to_csv('filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cef8d8a-d997-40b2-9113-7449fb43511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         122488\n",
      "critical        16638\n",
      "major           15988\n",
      "minor            7518\n",
      "trivial          3127\n",
      "blocker           800\n",
      "enhancement       225\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89cf7edd-6911-4dfc-b817-8fdc4ed8f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "normal =df[df.severity=='normal']\n",
    "major =df[df.severity=='major']\n",
    "minor =df[df.severity=='minor']\n",
    "blocker =df[df.severity=='blocker']\n",
    "trivial =df[df.severity=='trivial']\n",
    "critical =df[df.severity=='critical']\n",
    "enhancement =df[df.severity=='enhancement']\n",
    "\n",
    "def resample_df(df):\n",
    "    return resample(df,n_samples=30000)\n",
    "normal =resample_df(normal)\n",
    "major =resample_df(major)\n",
    "minor =resample_df(minor)\n",
    "blocker =resample_df(blocker)\n",
    "trivial =resample_df(trivial)\n",
    "critical =resample_df(critical)\n",
    "enhancement =resample_df(enhancement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75af1ac0-1c62-45d3-b2f0-ca10b6d75d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         30000\n",
      "major          30000\n",
      "minor          30000\n",
      "blocker        30000\n",
      "trivial        30000\n",
      "critical       30000\n",
      "enhancement    30000\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([normal,major,minor,blocker,trivial,critical,enhancement])\n",
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20456ca-fc2c-4cbe-9be0-7a060dae9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('filtered_oversampled.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
