{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d90b3f-8cc2-44bc-a318-6f4a201e158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48831244-9f29-4683-a1e8-a719bcaa90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bug_data.csv')\n",
    "df.head()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9b8f74-e55b-4930-951a-dccd9dab0ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "major       5000\n",
       "critical    5000\n",
       "minor       5000\n",
       "blocker     5000\n",
       "Name: severity, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "normal =df[df.severity=='normal']\n",
    "major =df[df.severity=='major']\n",
    "minor =df[df.severity=='minor']\n",
    "blocker =df[df.severity=='blocker']\n",
    "trivial =df[df.severity=='trivial']\n",
    "critical =df[df.severity=='critical']\n",
    "enhancement =df[df.severity=='enhancement']\n",
    "\n",
    "def resample_df(df):\n",
    "    return resample(df,replace=True,n_samples=5000)\n",
    "\n",
    "normal =resample_df(normal)\n",
    "major =resample_df(major)\n",
    "minor =resample_df(minor)\n",
    "blocker =resample_df(blocker)\n",
    "trivial =resample_df(trivial)\n",
    "critical =resample_df(critical)\n",
    "enhancement =resample_df(enhancement)\n",
    "\n",
    "df = pd.concat([major,critical,minor,blocker])\n",
    "\n",
    "\n",
    "df.severity.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22f0a28-5352-4432-aacb-2f0df4862430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 22s, sys: 10min 10s, total: 24min 33s\n",
      "Wall time: 10min 2s\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     blocker       0.67      0.82      0.74       977\n",
      "    critical       0.65      0.58      0.61      1024\n",
      "       major       0.45      0.43      0.44       995\n",
      "       minor       0.60      0.56      0.58      1004\n",
      "\n",
      "    accuracy                           0.60      4000\n",
      "   macro avg       0.59      0.60      0.59      4000\n",
      "weighted avg       0.59      0.60      0.59      4000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[798  45  86  48]\n",
      " [147 593 193  91]\n",
      " [158 168 430 239]\n",
      " [ 90 106 247 561]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Add your preprocessing steps here\n",
    "    return text\n",
    "\n",
    "df['description'] = df['description'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['description'])\n",
    "y = df['severity']\n",
    "\n",
    "# Split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train MLP model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)\n",
    "%time mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = mlp.predict(X_test)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
