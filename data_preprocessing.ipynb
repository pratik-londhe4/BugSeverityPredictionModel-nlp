{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7a689f-c9e4-4ad7-a102-93b73ba790c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform xml to csv it take 3 parameters inputfile with adreess output file with adreess and the name of the field\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def convert_xml_to_csv(input_file, output_file, field_name):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        \n",
    "        # Write CSV header\n",
    "        csvwriter.writerow(['id', field_name])\n",
    "        \n",
    "        # Write the CSV report\n",
    "        for report in root.findall('report'):\n",
    "            report_id = report.get('id')\n",
    "            for update in report.findall('update'):\n",
    "                field_value = update.find('what').text\n",
    "                csvwriter.writerow([report_id, field_value])\n",
    "    \n",
    "    print(f\"XML file {input_file} has been converted to CSV file {output_file} based on the field '{field_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3483a30-f553-4b63-8928-9a91aa97d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f4f6df-5c33-404d-8361-a97fed60e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function call for the converting xml to csv \n",
    "# input_file=\"mozilla/Bugzilla/severity.xml\"\n",
    "# output_file=\"processed_data/Bugzilla/severity.csv\"\n",
    "# convert_xml_to_csv(input_file, output_file, 'severity')\n",
    "\n",
    "# input_file=\"mozilla/Bugzilla/short_desc.xml\"\n",
    "# output_file=\"processed_data/Bugzilla/short_desc.csv\"\n",
    "# convert_xml_to_csv(input_file, output_file, 'description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf66787-7a0d-4fda-9f1b-489c5f862255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove duplication from the csv file \n",
    "\n",
    "def removeduplicate(input_file,output_file):\n",
    "    with open(input_file, 'r',encoding=\"utf-8\") as input_file, open(output_file, 'w', newline='',encoding=\"utf-8\") as output_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        writer = csv.writer(output_file)\n",
    "        seen = set()  # keep track of seen values\n",
    "        for row in reader:\n",
    "            if row[0] not in seen:  # if value hasn't been seen before\n",
    "                seen.add(row[0])\n",
    "                writer.writerow(row)\n",
    "        print(f\"all duplicates formm has been removed and output file is created \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e76db8-197c-4456-8f95-9fa75ef48c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call for removind duplicates in csv\n",
    "# input_file=\"processed_data/Bugzilla/severity.csv\"\n",
    "# output_file=\"processed_data/Bugzilla/severity_cleaned.csv\"\n",
    "# removeduplicate(input_file,output_file)\n",
    "\n",
    "# # function call for removind duplicates in csv\n",
    "# input_file=\"processed_data/Bugzilla/short_desc.csv\"\n",
    "# output_file=\"processed_data/Bugzilla/short_desc_cleaned.csv\"\n",
    "# removeduplicate(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52abbe21-9564-4b5c-83ee-0060bde3cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge 2 csv file\n",
    "def merge(file1,file2,output_file):\n",
    "    df = pd.read_csv(file1)\n",
    "    df1 = pd.read_csv(file2)\n",
    "\n",
    "    # Merge the data frames on the 'id' field\n",
    "    merged_df = pd.merge(df, df1, on='id', how='inner')\n",
    "\n",
    "    # Write the merged data frame to a CSV file\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"File merged\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3c00a3-0b35-4198-b7fa-ef05d70c2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file1 = \"processed_data/Bugzilla/severity_cleaned.csv\"\n",
    "# file2 = \"processed_data/Bugzilla/short_desc_cleaned.csv\"\n",
    "# output_file = \"processed_data/Bugzilla/Bugzilla.csv\"\n",
    "# merge(file1,file2,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d18dda90-f2d2-4b88-b441-88c33c9fc2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML file Bugzilla/severity.xml has been converted to CSV file processed_data/Bugzilla/severity.csv based on the field 'severity'.\n",
      "XML file Bugzilla/short_desc.xml has been converted to CSV file processed_data/Bugzilla/short_desc.csv based on the field 'description'.\n",
      "XML file Core/severity.xml has been converted to CSV file processed_data/Core/severity.csv based on the field 'severity'.\n",
      "XML file Core/short_desc.xml has been converted to CSV file processed_data/Core/short_desc.csv based on the field 'description'.\n",
      "XML file Firefox/severity.xml has been converted to CSV file processed_data/Firefox/severity.csv based on the field 'severity'.\n",
      "XML file Firefox/short_desc.xml has been converted to CSV file processed_data/Firefox/short_desc.csv based on the field 'description'.\n",
      "XML file Thunderbird/severity.xml has been converted to CSV file processed_data/Thunderbird/severity.csv based on the field 'severity'.\n",
      "XML file Thunderbird/short_desc.xml has been converted to CSV file processed_data/Thunderbird/short_desc.csv based on the field 'description'.\n"
     ]
    }
   ],
   "source": [
    "# list of list caontaing input file and output file infoe of each application\n",
    "file_info_xml_to_csv = [\n",
    "    [\"Bugzilla/severity.xml\", \"processed_data/Bugzilla/severity.csv\", \"severity\"],\n",
    "    [\"Bugzilla/short_desc.xml\", \"processed_data/Bugzilla/short_desc.csv\", \"description\"],\n",
    "    \n",
    "    [\"Core/severity.xml\", \"processed_data/Core/severity.csv\", \"severity\"],\n",
    "    [\"Core/short_desc.xml\", \"processed_data/Core/short_desc.csv\", \"description\"],\n",
    "    \n",
    "    [\"Firefox/severity.xml\", \"processed_data/Firefox/severity.csv\", \"severity\"],\n",
    "    [\"Firefox/short_desc.xml\", \"processed_data/Firefox/short_desc.csv\", \"description\"],\n",
    "    \n",
    "    [\"Thunderbird/severity.xml\", \"processed_data/Thunderbird/severity.csv\", \"severity\"],\n",
    "    [\"Thunderbird/short_desc.xml\", \"processed_data/Thunderbird/short_desc.csv\", \"description\"]\n",
    "]\n",
    "\n",
    "# for loop for acessing input file , output file and field name of each applicatin line by line and calling xml to csv function\n",
    "for info in file_info_xml_to_csv:\n",
    "    input_file = info[0]\n",
    "    output_file = info[1]\n",
    "    field_name = info[2]\n",
    "    convert_xml_to_csv(input_file, output_file, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c993f12-0681-4130-ad64-22f39e7b0b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n",
      "all duplicates formm has been removed and output file is created \n"
     ]
    }
   ],
   "source": [
    "# list of inputfile and outputfile for removing the duplicates \n",
    "file_info_remove_duplicate = [\n",
    "    [\"processed_data/Bugzilla/severity.csv\", \"processed_data/Bugzilla/severity_cleaned.csv\"],\n",
    "    [\"processed_data/Bugzilla/short_desc.csv\", \"processed_data/Bugzilla/short_desc_cleaned.csv\"],\n",
    "    \n",
    "    [\"processed_data/Core/severity.csv\", \"processed_data/Core/severity_cleaned.csv\"],\n",
    "    [\"processed_data/Core/short_desc.csv\", \"processed_data/Core/short_desc_cleaned.csv\"],\n",
    "    \n",
    "    [\"processed_data/Firefox/severity.csv\", \"processed_data/Firefox/severity_cleaned.csv\"],\n",
    "    [\"processed_data/Firefox/short_desc.csv\", \"processed_data/Firefox/short_desc_cleaned.csv\"],\n",
    "    \n",
    "    [\"processed_data/Thunderbird/severity.csv\", \"processed_data/Thunderbird/severity_cleaned.csv\"],\n",
    "    [\"processed_data/Thunderbird/short_desc.csv\", \"processed_data/Thunderbird/short_desc_cleaned.csv\"],\n",
    "]\n",
    "\n",
    "#for loop for acessing input file and output file and calling remove duplicate function\n",
    "\n",
    "for info in file_info_remove_duplicate:\n",
    "    input_file = info[0]\n",
    "    output_file = info[1]\n",
    "    removeduplicate(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409467e0-6031-4c93-9be4-0c446678d99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d260ac42-f846-4160-a7e7-3a49150739fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File merged\n",
      "File merged\n",
      "File merged\n",
      "File merged\n"
     ]
    }
   ],
   "source": [
    "# list of fules to merge \n",
    "file_info_merge = [\n",
    "    [\"processed_data/Bugzilla/severity_cleaned.csv\",\"processed_data/Bugzilla/short_desc_cleaned.csv\",\"processed_data/Bugzilla/Bugzilla_merged.csv\"],\n",
    "    \n",
    "    [\"processed_data/Core/severity_cleaned.csv\",\"processed_data/Core/short_desc_cleaned.csv\",\"processed_data/Core/Core_merged.csv\"],\n",
    "\n",
    "    [\"processed_data/Thunderbird/severity_cleaned.csv\",\"processed_data/Thunderbird/short_desc_cleaned.csv\",\"processed_data/Thunderbird/Thunderbird_merged.csv\"],\n",
    "    \n",
    "    [\"processed_data/Firefox/severity_cleaned.csv\",\"processed_data/Firefox/short_desc_cleaned.csv\",\"processed_data/Firefox/Firefox_merged.csv\"],\n",
    "    \n",
    "]\n",
    "\n",
    "for info in file_info_merge:\n",
    "    file1 = info[0]\n",
    "    file2 = info[1]\n",
    "    output_file = info[2]\n",
    "    merge(file1, file2, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b48647-7604-44c0-a431-9cc1b378b7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all file merged\n"
     ]
    }
   ],
   "source": [
    "file_info_merged = [\"processed_data/Bugzilla/Bugzilla_merged.csv\",\"processed_data/Core/Core_merged.csv\",\n",
    "                   \"processed_data/Thunderbird/Thunderbird_merged.csv\",\"processed_data/Firefox/Firefox_merged.csv\"\n",
    "                  ]\n",
    "\n",
    "# read in all four CSV files\n",
    "file1 = pd.read_csv(file_info_merged[0])\n",
    "file2 = pd.read_csv(file_info_merged[1])\n",
    "file3 = pd.read_csv(file_info_merged[2])\n",
    "file4 = pd.read_csv(file_info_merged[3])\n",
    "\n",
    "# merge the four files based on the 'id' field\n",
    "merged = pd.concat([file1, file2, file3, file4], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "#add numeric value to the severity\n",
    "\n",
    "\n",
    "# write the merged dataframe to a new CSV file\n",
    "merged.to_csv('data/all_app_merged.csv', index=False)\n",
    "print(\"all file merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f0a6f40-d22c-42b2-8f7b-43ed3dccb5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168024, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data/all_app_merged.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ac48e3a-e35c-4c1c-b72b-f3fc87193f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge tow preprocessed csv files containing bug data files\n",
    "df_pratik = pd.read_csv('bug_data.csv')\n",
    "df_sahil = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3302ddd7-9f38-474b-b761-a6e747814a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394660, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pratik.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a13be09-655e-4357-a77e-99cb497d6388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168024, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sahil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6c0e761-b009-4cbf-890a-e49177e79d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             168019\n",
      "description    168017\n",
      "severity       168019\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.concat([df_pratik,df_sahil])\n",
    "df_merged.shape\n",
    "#now remove duplicated from this to check if any new rows are found which were not there in df_sahil\n",
    "duplicate_ids = df_merged[df_merged.duplicated(['id'])]\n",
    "# Print the duplicate rows\n",
    "print(duplicate_ids.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d86409-e2e3-4c7a-8841-29bfec330fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e49807d-9e6d-4054-988b-d247d2da64e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322620</td>\n",
       "      <td>normal</td>\n",
       "      <td>Logging in with 'Remember my Login' deselected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>322807</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>a spelling's mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322837</td>\n",
       "      <td>normal</td>\n",
       "      <td>[RFE] Unsubscribe from bug you've reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322462</td>\n",
       "      <td>minor</td>\n",
       "      <td>LDAP Authentication: if LDAPbinddn is defined,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323100</td>\n",
       "      <td>normal</td>\n",
       "      <td>'Boundary' line removed from multipart message...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     severity                                        description\n",
       "0  322620       normal  Logging in with 'Remember my Login' deselected...\n",
       "1  322807  enhancement                               a spelling's mistake\n",
       "2  322837       normal         [RFE] Unsubscribe from bug you've reported\n",
       "3  322462        minor  LDAP Authentication: if LDAPbinddn is defined,...\n",
       "4  323100       normal  'Boundary' line removed from multipart message..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b1741a6-1057-43ac-963a-563bf3bdca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6502dd2d-e0ae-4ab4-969e-bfef7dc941c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "severity       0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85aee4f8-dbe4-47a3-9f75-73dea02d223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, severity, description]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicate_ids = df[df.duplicated(['id'])]\n",
    "# Print the duplicate rows\n",
    "print(duplicate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1b53bc5-b201-43c4-97b2-128c426d2fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         123472\n",
      "critical        16736\n",
      "major           16067\n",
      "minor            7546\n",
      "trivial          3165\n",
      "blocker           806\n",
      "enhancement       225\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df['severity'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c92684b-dc32-4a0f-ab1b-9b0d573084af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322620</td>\n",
       "      <td>normal</td>\n",
       "      <td>Logging in with 'Remember my Login' deselected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322837</td>\n",
       "      <td>normal</td>\n",
       "      <td>[RFE] Unsubscribe from bug you've reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323100</td>\n",
       "      <td>normal</td>\n",
       "      <td>'Boundary' line removed from multipart message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>323769</td>\n",
       "      <td>normal</td>\n",
       "      <td>\"Invalid Column Name\" when exportign bug list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>327624</td>\n",
       "      <td>normal</td>\n",
       "      <td>Missing space in attachment size error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id severity                                        description\n",
       "0   322620   normal  Logging in with 'Remember my Login' deselected...\n",
       "2   322837   normal         [RFE] Unsubscribe from bug you've reported\n",
       "4   323100   normal  'Boundary' line removed from multipart message...\n",
       "6   323769   normal  \"Invalid Column Name\" when exportign bug list ...\n",
       "11  327624   normal             Missing space in attachment size error"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove bug with severity as enhancement\n",
    "normal =df[df.severity=='normal']\n",
    "major =df[df.severity=='major']\n",
    "minor =df[df.severity=='minor']\n",
    "blocker =df[df.severity=='blocker']\n",
    "trivial =df[df.severity=='trivial']\n",
    "critical =df[df.severity=='critical']\n",
    "enhancement =df[df.severity=='enhancement']\n",
    "\n",
    "df_pre = pd.concat([normal,major,minor,blocker,trivial,critical])\n",
    "\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "813c58fb-a55f-467d-b36d-3ce0b6ed6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         123472\n",
      "major          123472\n",
      "minor          123472\n",
      "blocker        123472\n",
      "trivial        123472\n",
      "critical       123472\n",
      "enhancement    123472\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#code for resampling the data as class imbalance is observed\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def resample_df(df):\n",
    "    return resample(df,n_samples=123472)\n",
    "\n",
    "major =resample_df(major)\n",
    "minor =resample_df(minor)\n",
    "blocker =resample_df(blocker)\n",
    "trivial =resample_df(trivial)\n",
    "critical =resample_df(critical)\n",
    "enhancement =resample_df(enhancement)\n",
    "\n",
    "df = pd.concat([normal,major,minor,blocker,trivial,critical,enhancement])\n",
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4eff505f-6e58-4d41-8650-1f0d08af9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give severity a numeric value\n",
    "# give numeric values to the severitys\n",
    "df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4,'trivial' : 5, 'enhancement' : 6})\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4})\n",
    "\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "948fe4f3-15e0-4e2c-a954-1dcb40061df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity</th>\n",
       "      <th>description</th>\n",
       "      <th>severity_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322620</td>\n",
       "      <td>normal</td>\n",
       "      <td>Logging in with 'Remember my Login' deselected...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322837</td>\n",
       "      <td>normal</td>\n",
       "      <td>[RFE] Unsubscribe from bug you've reported</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323100</td>\n",
       "      <td>normal</td>\n",
       "      <td>'Boundary' line removed from multipart message...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>323769</td>\n",
       "      <td>normal</td>\n",
       "      <td>\"Invalid Column Name\" when exportign bug list ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>327624</td>\n",
       "      <td>normal</td>\n",
       "      <td>Missing space in attachment size error</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id severity                                        description  \\\n",
       "0   322620   normal  Logging in with 'Remember my Login' deselected...   \n",
       "2   322837   normal         [RFE] Unsubscribe from bug you've reported   \n",
       "4   323100   normal  'Boundary' line removed from multipart message...   \n",
       "6   323769   normal  \"Invalid Column Name\" when exportign bug list ...   \n",
       "11  327624   normal             Missing space in attachment size error   \n",
       "\n",
       "    severity_num  \n",
       "0              1  \n",
       "2              1  \n",
       "4              1  \n",
       "6              1  \n",
       "11             1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('data/oversampled.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4dbe1f7d-8c84-44a8-a6d4-148253e86d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/oversampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b54deb3-2adb-4420-9b13-0e17574e3f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864304, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "554dc5d3-fe7d-41eb-9f99-2aea8694deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Read in the merged CSV file\n",
    "df = pd.read_csv('data/all_app_merged.csv')\n",
    "\n",
    "# Filter out rows where the description only contains one word\n",
    "df = df[df['description'].apply(lambda x: len(str(x).split()) > 1)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "df.to_csv('filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cef8d8a-d997-40b2-9113-7449fb43511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         122488\n",
      "critical        16638\n",
      "major           15988\n",
      "minor            7518\n",
      "trivial          3127\n",
      "blocker           800\n",
      "enhancement       225\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "89cf7edd-6911-4dfc-b817-8fdc4ed8f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "normal =df[df.severity=='normal']\n",
    "major =df[df.severity=='major']\n",
    "minor =df[df.severity=='minor']\n",
    "blocker =df[df.severity=='blocker']\n",
    "trivial =df[df.severity=='trivial']\n",
    "critical =df[df.severity=='critical']\n",
    "enhancement =df[df.severity=='enhancement']\n",
    "\n",
    "def resample_df(df):\n",
    "    return resample(df,n_samples=30000)\n",
    "normal =resample_df(normal)\n",
    "major =resample_df(major)\n",
    "minor =resample_df(minor)\n",
    "blocker =resample_df(blocker)\n",
    "trivial =resample_df(trivial)\n",
    "critical =resample_df(critical)\n",
    "enhancement =resample_df(enhancement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75af1ac0-1c62-45d3-b2f0-ca10b6d75d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         30000\n",
      "major          30000\n",
      "minor          30000\n",
      "blocker        30000\n",
      "trivial        30000\n",
      "critical       30000\n",
      "enhancement    30000\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([normal,major,minor,blocker,trivial,critical,enhancement])\n",
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0afa418-3c60-489c-92de-c000b185f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give severity a numeric value\n",
    "# give numeric values to the severitys\n",
    "df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4,'trivial' : 5, 'enhancement' : 6})\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4})\n",
    "\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b20456ca-fc2c-4cbe-9be0-7a060dae9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/filtered_oversampled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0acaac4a-f578-40bc-948a-95714dc4e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give severity a numeric value\n",
    "# give numeric values to the severitys\n",
    "df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4,'trivial' : 5, 'enhancement' : 6})\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4})\n",
    "\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c9ce135b-0f5d-4eae-b17f-9b5fe7ba7dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30000\n",
       "2    30000\n",
       "0    30000\n",
       "4    30000\n",
       "5    30000\n",
       "3    30000\n",
       "6    30000\n",
       "Name: severity_num, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['severity_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde33d8-9c33-4618-a796-ad61436e0f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2c3791ac-511b-4d0a-ba99-5559691602bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bug_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6e170b83-2088-491d-bb49-25863d19e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give severity a numeric value\n",
    "# give numeric values to the severitys\n",
    "df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4,'trivial' : 5, 'enhancement' : 6})\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3,'blocker':4})\n",
    "\n",
    "# df['severity_num'] = df.severity.map({'minor':0,'normal':1,'major':2,'critical':3})\n",
    "df = df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ddd1472-cfc4-4028-95aa-18b742ad15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "normal =df[df.severity=='normal']\n",
    "major =df[df.severity=='major']\n",
    "minor =df[df.severity=='minor']\n",
    "blocker =df[df.severity=='blocker']\n",
    "trivial =df[df.severity=='trivial']\n",
    "critical =df[df.severity=='critical']\n",
    "enhancement =df[df.severity=='enhancement']\n",
    "\n",
    "def resample_df(df):\n",
    "    return resample(df,n_samples=50000)\n",
    "\n",
    "normal =resample_df(normal)\n",
    "major =resample_df(major)\n",
    "minor =resample_df(minor)\n",
    "blocker =resample_df(blocker)\n",
    "trivial =resample_df(trivial)\n",
    "critical =resample_df(critical)\n",
    "enhancement =resample_df(enhancement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "33d66ac8-4670-4d6b-9d25-4081fd81e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal         50000\n",
      "major          50000\n",
      "minor          50000\n",
      "blocker        50000\n",
      "trivial        50000\n",
      "critical       50000\n",
      "enhancement    50000\n",
      "Name: severity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([normal,major,minor,blocker,trivial,critical,enhancement])\n",
    "\n",
    "counts = df['severity'].value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "19d9d027-a665-4f3a-9073-ec3fdf7ed81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(\"severity_num\",axis=1)\n",
    "df.to_csv('bug_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8032693-03c0-4b3d-91b3-544bd3a4fa11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
